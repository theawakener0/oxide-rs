[package]
name = "oxide-rs"
version = "0.1.0"
edition = "2024"
license = "MIT"
description = "AI Inference library and CLI in Rust - llama.cpp style"
repository = "https://github.com/theawakener0/oxide"
keywords = ["llm", "inference", "gguf", "candle", "machine-learning"]
categories = ["science", "command-line-utilities"]

[dependencies]
candle-core = "0.9"
candle-nn = "0.9"
candle-transformers = "0.9"
tokenizers = "0.19"
shimmytok = "0.7"
memmap2 = "0.9"
crossterm = "0.28"
minijinja = "2.4"
anyhow = "1.0"
clap = { version = "4.5", features = ["derive"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
num_cpus = "1.16"
sha2 = "0.10"
libc = "0.2"

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
